{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy_of_Copy_of_Deploy.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"_D10eR-K1uXg"},"source":["## Please run this notebook in colab or any GPU backend system"]},{"cell_type":"code","metadata":{"id":"vX_3cMbKAIwK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621834655085,"user_tz":-330,"elapsed":1296,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"2ca9f481-3099-4449-bfcf-d2aed47e56a5"},"source":["%cd /content\n","!mkdir traning_demo\n","!mkdir traning_demo/pre-trained-models\n","!mkdir traning_demo/annotations\n","!mkdir traning_demo/export_model"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V4IyhqFPdyCx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621834734232,"user_tz":-330,"elapsed":74292,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"c913d1e8-53cf-47a9-f684-3207aed4cee4"},"source":["!pip install tensorflow-gpu"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/a2/5ccf0a418eb22e0a2ae9edc1e7f5456d0a4b8b49524572897564b4030a9b/tensorflow_gpu-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3MB)\n","\u001b[K     |████████████████████████████████| 454.3MB 36kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.7.4.3)\n","Collecting grpcio~=1.34.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/d1/f38a91d8724706427fe973a7dfa11e938cee98aa7196b03d870a25a08bab/grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0MB)\n","\u001b[K     |████████████████████████████████| 4.0MB 33.6MB/s \n","\u001b[?25hCollecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/78/b27f73e923becc6e79e18fe112cf75e3200d1ee35b0dba8fa46181bce56c/tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462kB)\n","\u001b[K     |████████████████████████████████| 471kB 32.2MB/s \n","\u001b[?25hRequirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12)\n","Collecting tensorboard~=2.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/f5/7feea02a3fb54d5db827ac4b822a7ba8933826b36de21880518250b8733a/tensorboard-2.5.0-py3-none-any.whl (6.0MB)\n","\u001b[K     |████████████████████████████████| 6.0MB 30.0MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.12.4)\n","Collecting gast==0.4.0\n","  Downloading https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12.1)\n","Collecting h5py~=3.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/74/9eae2bedd8201ab464308f42c601a12d79727a1c87f0c867fdefb212c6cf/h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n","\u001b[K     |████████████████████████████████| 4.0MB 31.6MB/s \n","\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.36.2)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n","Collecting keras-nightly~=2.5.0.dev\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/e7/53bc896aa4e11a87aac10a625c676b3a3d57d1c8d9929e4809d31fa0b7d5/keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 28.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.19.5)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.12.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/f9/802efd84988bffd9f644c03b6e66fde8e76c3aa33db4279ddd11c5d61f4b/tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9MB)\n","\u001b[K     |████████████████████████████████| 4.9MB 32.9MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (1.8.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (1.30.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (2.0.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (0.4.4)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (56.1.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (2.23.0)\n","Collecting cached-property; python_version < \"3.8\"\n","  Downloading https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (4.2.2)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow-gpu) (4.0.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu) (1.3.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (3.0.4)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow-gpu) (3.4.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu) (3.1.0)\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement grpcio~=1.32.0, but you'll have grpcio 1.34.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement h5py~=2.10.0, but you'll have h5py 3.1.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorflow-estimator<2.5.0,>=2.4.0, but you'll have tensorflow-estimator 2.5.0 which is incompatible.\u001b[0m\n","Installing collected packages: grpcio, tensorflow-estimator, tensorboard-data-server, tensorboard, gast, cached-property, h5py, keras-nightly, tensorflow-gpu\n","  Found existing installation: grpcio 1.32.0\n","    Uninstalling grpcio-1.32.0:\n","      Successfully uninstalled grpcio-1.32.0\n","  Found existing installation: tensorflow-estimator 2.4.0\n","    Uninstalling tensorflow-estimator-2.4.0:\n","      Successfully uninstalled tensorflow-estimator-2.4.0\n","  Found existing installation: tensorboard 2.4.1\n","    Uninstalling tensorboard-2.4.1:\n","      Successfully uninstalled tensorboard-2.4.1\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: h5py 2.10.0\n","    Uninstalling h5py-2.10.0:\n","      Successfully uninstalled h5py-2.10.0\n","Successfully installed cached-property-1.5.2 gast-0.4.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorflow-estimator-2.5.0 tensorflow-gpu-2.5.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"axPd-0oRITOe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621834760220,"user_tz":-330,"elapsed":1957,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"ddc41ae5-c4a6-4ab3-ba3f-dc0cb07a045b"},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["2.5.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"egsDMFq8OLcZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621834794909,"user_tz":-330,"elapsed":25919,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"82d215cb-74cc-431e-fb67-1960ad405899"},"source":["!git clone https://github.com/tensorflow/models.git"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Cloning into 'models'...\n","remote: Enumerating objects: 57199, done.\u001b[K\n","remote: Counting objects: 100% (1287/1287), done.\u001b[K\n","remote: Compressing objects: 100% (489/489), done.\u001b[K\n","remote: Total 57199 (delta 890), reused 1156 (delta 782), pack-reused 55912\u001b[K\n","Receiving objects: 100% (57199/57199), 572.84 MiB | 27.62 MiB/s, done.\n","Resolving deltas: 100% (39538/39538), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"we7Z5YNBOOcS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621834794910,"user_tz":-330,"elapsed":13,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"1b4a3c03-9a4b-440b-b742-a22683c3e545"},"source":["%cd /content/models/research"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D0duZwjfOUDk","executionInfo":{"status":"ok","timestamp":1621834805039,"user_tz":-330,"elapsed":563,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["!protoc object_detection/protos/*.proto --python_out=."],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"3yvUs-unROUL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621834810785,"user_tz":-330,"elapsed":2063,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"f849e7be-b695-4d55-e915-157c8e5694ca"},"source":["!git clone https://github.com/cocodataset/cocoapi.git"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Cloning into 'cocoapi'...\n","remote: Enumerating objects: 975, done.\u001b[K\n","remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n","Receiving objects: 100% (975/975), 11.72 MiB | 16.74 MiB/s, done.\n","Resolving deltas: 100% (576/576), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2uSRXJ7dRSvb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621834827875,"user_tz":-330,"elapsed":5,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"731b9803-9ce9-41da-8be4-7cbbf3f2d078"},"source":["%cd cocoapi/PythonAPI"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/content/models/research/cocoapi/PythonAPI\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ub6XmU1TRYLT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621834839547,"user_tz":-330,"elapsed":6640,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"3bcbec0a-5f7b-4e17-8dae-4bfcddc05b4f"},"source":["!make"],"execution_count":9,"outputs":[{"output_type":"stream","text":["python setup.py build_ext --inplace\n","running build_ext\n","cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n","/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/models/research/cocoapi/PythonAPI/pycocotools/_mask.pyx\n","  tree = Parsing.p_module(s, pxd, full_module_name)\n","building 'pycocotools._mask' extension\n","creating build\n","creating build/common\n","creating build/temp.linux-x86_64-3.7\n","creating build/temp.linux-x86_64-3.7/pycocotools\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n","       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n","                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n","   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n","                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n","   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n","                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n","       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n","       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n","                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n","   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n","   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n","                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n","     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n","     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n","                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n","       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n","                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n","creating build/lib.linux-x86_64-3.7\n","creating build/lib.linux-x86_64-3.7/pycocotools\n","x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n","copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n","rm -rf build\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MWeSBPODRZvS","executionInfo":{"status":"ok","timestamp":1621834868667,"user_tz":-330,"elapsed":449,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["%cp -r pycocotools /content/models/research"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"OPNe5G_YRdh9","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1621834876352,"user_tz":-330,"elapsed":493,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"ec668093-b54c-48cf-bb79-5185660e5652"},"source":["%pwd"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/models/research/cocoapi/PythonAPI'"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"YDaiORV7RmJz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621834887678,"user_tz":-330,"elapsed":822,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"57f29773-79f6-48a7-c3fe-f03d06bf482f"},"source":["%cd ../.."],"execution_count":12,"outputs":[{"output_type":"stream","text":["/content/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Icv4Duv8RoAz","executionInfo":{"status":"ok","timestamp":1621834892080,"user_tz":-330,"elapsed":517,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["%cp object_detection/packages/tf2/setup.py ."],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"E0oEwWDiRqMO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621834992715,"user_tz":-330,"elapsed":96333,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"05fbc86e-acb0-4dbf-f905-91316bb266de"},"source":["!python -m pip install ."],"execution_count":14,"outputs":[{"output_type":"stream","text":["Processing /content/models/research\n","Collecting avro-python3\n","  Downloading https://files.pythonhosted.org/packages/cc/97/7a6970380ca8db9139a3cc0b0e3e0dd3e4bc584fb3644e1d06e71e1a55f0/avro-python3-1.10.2.tar.gz\n","Collecting apache-beam\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/7f/342e6bf4bbdc55418c929b3281948070ef4ca83e198dc9135352c25799f9/apache_beam-2.29.0-cp37-cp37m-manylinux2010_x86_64.whl (9.6MB)\n","\u001b[K     |████████████████████████████████| 9.6MB 16.5MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.23)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n","\u001b[K     |████████████████████████████████| 358kB 36.9MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n","Collecting lvis\n","  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n","Collecting tf-models-official\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/08/81bbc275e8e9c6d1e03dd26daec3a67f45e6322804cbce3d51f93eae1961/tf_models_official-2.5.0-py2.py3-none-any.whl (1.6MB)\n","\u001b[K     |████████████████████████████████| 1.6MB 36.0MB/s \n","\u001b[?25hCollecting future<1.0.0,>=0.18.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n","\u001b[K     |████████████████████████████████| 829kB 32.8MB/s \n","\u001b[?25hCollecting fastavro<2,>=0.21.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/d1/8f5c8611026f0ddcd86a8e2f965998e0c159af980c31efba72342c69f3e4/fastavro-1.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 28.0MB/s \n","\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.34.1)\n","Collecting hdfs<3.0.0,>=2.1.0\n","  Downloading https://files.pythonhosted.org/packages/08/f7/4c3fad73123a24d7394b6f40d1ec9c1cbf2e921cfea1797216ffd0a51fb1/hdfs-2.6.0-py3-none-any.whl\n","Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n","Requirement already satisfied: pyarrow<4.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n","Collecting dill<0.3.2,>=0.3.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n","\u001b[K     |████████████████████████████████| 153kB 43.7MB/s \n","\u001b[?25hRequirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n","Collecting requests<3.0.0,>=2.24.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.5MB/s \n","\u001b[?25hRequirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.11.4)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.4)\n","Requirement already satisfied: numpy<1.21.0,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.19.5)\n","Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n","Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->object-detection==0.1) (56.1.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Collecting tensorflow-addons\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n","\u001b[K     |████████████████████████████████| 686kB 31.7MB/s \n","\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.5.12)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 31.8MB/s \n","\u001b[?25hCollecting sacrebleu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.4MB/s \n","\u001b[?25hRequirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n","Collecting tensorflow-model-optimization>=0.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n","\u001b[K     |████████████████████████████████| 174kB 40.5MB/s \n","\u001b[?25hCollecting tensorflow>=2.5.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/fd/993aa1333eb54d9f000863fe8ec61e41d12eb833dea51484c76c038718b5/tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3MB)\n","\u001b[K     |████████████████████████████████| 454.3MB 34kB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.12.0)\n","Collecting seqeval\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n","\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.12.8)\n","Collecting pyyaml>=5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n","\u001b[K     |████████████████████████████████| 645kB 35.0MB/s \n","\u001b[?25hCollecting py-cpuinfo>=3.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/ba/77120e44cbe9719152415b97d5bfb29f4053ee987d6cb63f55ce7d50fadc/py-cpuinfo-8.0.0.tar.gz (99kB)\n","\u001b[K     |████████████████████████████████| 102kB 10.1MB/s \n","\u001b[?25hCollecting opencv-python-headless\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/84/72ec52fbac4775c2a5bf0ee5573c922a0cac35eb841907edf56493a5e313/opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2MB)\n","\u001b[K     |████████████████████████████████| 38.2MB 80kB/s \n","\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.12.5)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (5.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.41.1)\n","Collecting portalocker==2.0.0\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n","Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official->object-detection==0.1) (0.1.6)\n","Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0.dev2021032900)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.36.2)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12.1)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (5.1.2)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.30.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (21.2.0)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official->object-detection==0.1) (0.22.2.post1)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.30.0)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.26.3)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n","Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.0.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.4)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.8.0)\n","Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.1)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official->object-detection==0.1) (1.53.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.2)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (20.9)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.0)\n","Building wheels for collected packages: object-detection, avro-python3, future, dill, seqeval, py-cpuinfo\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-cp37-none-any.whl size=1650082 sha256=a2b0cbb737272c978a36df1f91ceba99596337c7cf00d796125508d316ee5a46\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-r6y1njev/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-cp37-none-any.whl size=44011 sha256=0c48b172a3083963eb7ab50d4d2f26bbea0b3293ba6e78c195a8b63f963cb33a\n","  Stored in directory: /root/.cache/pip/wheels/ee/ee/18/c466221ca6900e3efce2f4ea9c329288808679aecdcb2838d3\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=98fddbd91a37b83e41628011777055bef40b8fcfea96dcc24ce36044cacc91b4\n","  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-cp37-none-any.whl size=78532 sha256=7f49b682cb17fd548d6f7399de1ae51945d04281a7bf186c398593275feac32f\n","  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=888cf56cb1ef21cfee8afba6fc2beb0ccb61d4770f713f32ebec4012ad1ba555\n","  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-cp37-none-any.whl size=22245 sha256=8680f83b4dc3b6c570922efa449bca31e720b3aa7bbe9356e18b2142bc27be1b\n","  Stored in directory: /root/.cache/pip/wheels/2e/15/f5/aa2a056d223903b52cf4870134e3a01df0c723816835dd08db\n","Successfully built object-detection avro-python3 future dill seqeval py-cpuinfo\n","\u001b[31mERROR: multiprocess 0.70.11.1 has requirement dill>=0.3.3, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: apache-beam 2.29.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.2 which is incompatible.\u001b[0m\n","Installing collected packages: avro-python3, future, fastavro, requests, hdfs, dill, apache-beam, tf-slim, lvis, tensorflow-addons, sentencepiece, portalocker, sacrebleu, tensorflow-model-optimization, tensorflow, seqeval, pyyaml, py-cpuinfo, opencv-python-headless, tf-models-official, object-detection\n","  Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Found existing installation: dill 0.3.3\n","    Uninstalling dill-0.3.3:\n","      Successfully uninstalled dill-0.3.3\n","  Found existing installation: tensorflow 2.4.1\n","    Uninstalling tensorflow-2.4.1:\n","      Successfully uninstalled tensorflow-2.4.1\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed apache-beam-2.29.0 avro-python3-1.10.2 dill-0.3.1.1 fastavro-1.4.1 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.2.52 portalocker-2.0.0 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.25.1 sacrebleu-1.5.1 sentencepiece-0.1.95 seqeval-1.2.2 tensorflow-2.5.0 tensorflow-addons-0.13.0 tensorflow-model-optimization-0.5.0 tf-models-official-2.5.0 tf-slim-1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SfPZ-fIpRrys","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621835045787,"user_tz":-330,"elapsed":40252,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"c59fa974-33f2-48cb-b564-06554a8edac8"},"source":["!python object_detection/builders/model_builder_tf2_test.py"],"execution_count":15,"outputs":[{"output_type":"stream","text":["2021-05-24 05:43:29.635815: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","Running tests under Python 3.7.10: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","2021-05-24 05:43:32.299321: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n","2021-05-24 05:43:32.359708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-24 05:43:32.360803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n","coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n","2021-05-24 05:43:32.360853: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","2021-05-24 05:43:32.523183: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n","2021-05-24 05:43:32.523286: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n","2021-05-24 05:43:32.676217: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n","2021-05-24 05:43:32.699448: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n","2021-05-24 05:43:32.699703: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2021-05-24 05:43:32.722380: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n","2021-05-24 05:43:32.731182: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n","2021-05-24 05:43:32.731226: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","2021-05-24 05:43:32.731783: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-05-24 05:43:32.731992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-05-24 05:43:32.732042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n","W0524 05:43:33.010390 140275655579520 model_builder.py:1061] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.04s\n","I0524 05:43:33.329842 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.04s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.66s\n","I0524 05:43:33.993327 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.66s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.33s\n","I0524 05:43:34.326323 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.33s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.29s\n","I0524 05:43:34.617679 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.29s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","W0524 05:43:34.620233 140275655579520 mobilenet_v2.py:296] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","9412608/9406464 [==============================] - 0s 0us/step\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.55s\n","I0524 05:43:37.170286 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.55s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0524 05:43:37.171542 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","I0524 05:43:37.198739 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","I0524 05:43:37.215691 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","I0524 05:43:37.233058 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n","I0524 05:43:37.354835 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n","I0524 05:43:37.468204 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n","I0524 05:43:37.582739 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.12s\n","I0524 05:43:37.700591 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.12s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.11s\n","I0524 05:43:37.809956 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","I0524 05:43:37.840772 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0524 05:43:38.047393 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0524 05:43:38.047600 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n","I0524 05:43:38.047701 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n","I0524 05:43:38.049940 140275655579520 efficientnet_model.py:147] round_filter input=32 output=32\n","I0524 05:43:38.067930 140275655579520 efficientnet_model.py:147] round_filter input=32 output=32\n","I0524 05:43:38.068054 140275655579520 efficientnet_model.py:147] round_filter input=16 output=16\n","I0524 05:43:38.137113 140275655579520 efficientnet_model.py:147] round_filter input=16 output=16\n","I0524 05:43:38.137242 140275655579520 efficientnet_model.py:147] round_filter input=24 output=24\n","I0524 05:43:38.310784 140275655579520 efficientnet_model.py:147] round_filter input=24 output=24\n","I0524 05:43:38.310926 140275655579520 efficientnet_model.py:147] round_filter input=40 output=40\n","I0524 05:43:38.493326 140275655579520 efficientnet_model.py:147] round_filter input=40 output=40\n","I0524 05:43:38.493634 140275655579520 efficientnet_model.py:147] round_filter input=80 output=80\n","I0524 05:43:38.937516 140275655579520 efficientnet_model.py:147] round_filter input=80 output=80\n","I0524 05:43:38.937785 140275655579520 efficientnet_model.py:147] round_filter input=112 output=112\n","I0524 05:43:39.215955 140275655579520 efficientnet_model.py:147] round_filter input=112 output=112\n","I0524 05:43:39.216154 140275655579520 efficientnet_model.py:147] round_filter input=192 output=192\n","I0524 05:43:39.620024 140275655579520 efficientnet_model.py:147] round_filter input=192 output=192\n","I0524 05:43:39.620221 140275655579520 efficientnet_model.py:147] round_filter input=320 output=320\n","I0524 05:43:39.726011 140275655579520 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0524 05:43:39.782187 140275655579520 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0524 05:43:39.840081 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0524 05:43:39.840209 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n","I0524 05:43:39.840310 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n","I0524 05:43:39.842219 140275655579520 efficientnet_model.py:147] round_filter input=32 output=32\n","I0524 05:43:39.859814 140275655579520 efficientnet_model.py:147] round_filter input=32 output=32\n","I0524 05:43:39.859986 140275655579520 efficientnet_model.py:147] round_filter input=16 output=16\n","I0524 05:43:40.002883 140275655579520 efficientnet_model.py:147] round_filter input=16 output=16\n","I0524 05:43:40.003134 140275655579520 efficientnet_model.py:147] round_filter input=24 output=24\n","I0524 05:43:40.269172 140275655579520 efficientnet_model.py:147] round_filter input=24 output=24\n","I0524 05:43:40.269382 140275655579520 efficientnet_model.py:147] round_filter input=40 output=40\n","I0524 05:43:40.539128 140275655579520 efficientnet_model.py:147] round_filter input=40 output=40\n","I0524 05:43:40.539309 140275655579520 efficientnet_model.py:147] round_filter input=80 output=80\n","I0524 05:43:40.923240 140275655579520 efficientnet_model.py:147] round_filter input=80 output=80\n","I0524 05:43:40.923465 140275655579520 efficientnet_model.py:147] round_filter input=112 output=112\n","I0524 05:43:41.291640 140275655579520 efficientnet_model.py:147] round_filter input=112 output=112\n","I0524 05:43:41.291851 140275655579520 efficientnet_model.py:147] round_filter input=192 output=192\n","I0524 05:43:41.811143 140275655579520 efficientnet_model.py:147] round_filter input=192 output=192\n","I0524 05:43:41.811380 140275655579520 efficientnet_model.py:147] round_filter input=320 output=320\n","I0524 05:43:42.042956 140275655579520 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0524 05:43:42.100420 140275655579520 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0524 05:43:42.173196 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0524 05:43:42.173470 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n","I0524 05:43:42.173587 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n","I0524 05:43:42.175553 140275655579520 efficientnet_model.py:147] round_filter input=32 output=32\n","I0524 05:43:42.193350 140275655579520 efficientnet_model.py:147] round_filter input=32 output=32\n","I0524 05:43:42.193521 140275655579520 efficientnet_model.py:147] round_filter input=16 output=16\n","I0524 05:43:42.342517 140275655579520 efficientnet_model.py:147] round_filter input=16 output=16\n","I0524 05:43:42.342661 140275655579520 efficientnet_model.py:147] round_filter input=24 output=24\n","I0524 05:43:42.749953 140275655579520 efficientnet_model.py:147] round_filter input=24 output=24\n","I0524 05:43:42.750200 140275655579520 efficientnet_model.py:147] round_filter input=40 output=48\n","I0524 05:43:43.024391 140275655579520 efficientnet_model.py:147] round_filter input=40 output=48\n","I0524 05:43:43.024589 140275655579520 efficientnet_model.py:147] round_filter input=80 output=88\n","I0524 05:43:43.386021 140275655579520 efficientnet_model.py:147] round_filter input=80 output=88\n","I0524 05:43:43.386209 140275655579520 efficientnet_model.py:147] round_filter input=112 output=120\n","I0524 05:43:43.766192 140275655579520 efficientnet_model.py:147] round_filter input=112 output=120\n","I0524 05:43:43.766560 140275655579520 efficientnet_model.py:147] round_filter input=192 output=208\n","I0524 05:43:44.297617 140275655579520 efficientnet_model.py:147] round_filter input=192 output=208\n","I0524 05:43:44.297849 140275655579520 efficientnet_model.py:147] round_filter input=320 output=352\n","I0524 05:43:44.550035 140275655579520 efficientnet_model.py:147] round_filter input=1280 output=1408\n","I0524 05:43:44.610001 140275655579520 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0524 05:43:44.680350 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0524 05:43:44.680556 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n","I0524 05:43:44.680673 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n","I0524 05:43:44.682585 140275655579520 efficientnet_model.py:147] round_filter input=32 output=40\n","I0524 05:43:44.700868 140275655579520 efficientnet_model.py:147] round_filter input=32 output=40\n","I0524 05:43:44.701000 140275655579520 efficientnet_model.py:147] round_filter input=16 output=24\n","I0524 05:43:44.842081 140275655579520 efficientnet_model.py:147] round_filter input=16 output=24\n","I0524 05:43:44.842226 140275655579520 efficientnet_model.py:147] round_filter input=24 output=32\n","I0524 05:43:45.115934 140275655579520 efficientnet_model.py:147] round_filter input=24 output=32\n","I0524 05:43:45.116103 140275655579520 efficientnet_model.py:147] round_filter input=40 output=48\n","I0524 05:43:45.385521 140275655579520 efficientnet_model.py:147] round_filter input=40 output=48\n","I0524 05:43:45.385711 140275655579520 efficientnet_model.py:147] round_filter input=80 output=96\n","I0524 05:43:45.839914 140275655579520 efficientnet_model.py:147] round_filter input=80 output=96\n","I0524 05:43:45.840110 140275655579520 efficientnet_model.py:147] round_filter input=112 output=136\n","I0524 05:43:46.313440 140275655579520 efficientnet_model.py:147] round_filter input=112 output=136\n","I0524 05:43:46.313717 140275655579520 efficientnet_model.py:147] round_filter input=192 output=232\n","I0524 05:43:46.947712 140275655579520 efficientnet_model.py:147] round_filter input=192 output=232\n","I0524 05:43:46.947911 140275655579520 efficientnet_model.py:147] round_filter input=320 output=384\n","I0524 05:43:47.375503 140275655579520 efficientnet_model.py:147] round_filter input=1280 output=1536\n","I0524 05:43:47.442292 140275655579520 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0524 05:43:47.539921 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0524 05:43:47.540182 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n","I0524 05:43:47.540344 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n","I0524 05:43:47.542474 140275655579520 efficientnet_model.py:147] round_filter input=32 output=48\n","I0524 05:43:47.561030 140275655579520 efficientnet_model.py:147] round_filter input=32 output=48\n","I0524 05:43:47.561166 140275655579520 efficientnet_model.py:147] round_filter input=16 output=24\n","I0524 05:43:47.703599 140275655579520 efficientnet_model.py:147] round_filter input=16 output=24\n","I0524 05:43:47.703750 140275655579520 efficientnet_model.py:147] round_filter input=24 output=32\n","I0524 05:43:48.060464 140275655579520 efficientnet_model.py:147] round_filter input=24 output=32\n","I0524 05:43:48.060641 140275655579520 efficientnet_model.py:147] round_filter input=40 output=56\n","I0524 05:43:48.418360 140275655579520 efficientnet_model.py:147] round_filter input=40 output=56\n","I0524 05:43:48.418586 140275655579520 efficientnet_model.py:147] round_filter input=80 output=112\n","I0524 05:43:48.983661 140275655579520 efficientnet_model.py:147] round_filter input=80 output=112\n","I0524 05:43:48.983891 140275655579520 efficientnet_model.py:147] round_filter input=112 output=160\n","I0524 05:43:49.585158 140275655579520 efficientnet_model.py:147] round_filter input=112 output=160\n","I0524 05:43:49.585362 140275655579520 efficientnet_model.py:147] round_filter input=192 output=272\n","I0524 05:43:50.494642 140275655579520 efficientnet_model.py:147] round_filter input=192 output=272\n","I0524 05:43:50.494900 140275655579520 efficientnet_model.py:147] round_filter input=320 output=448\n","I0524 05:43:50.791081 140275655579520 efficientnet_model.py:147] round_filter input=1280 output=1792\n","I0524 05:43:50.858685 140275655579520 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0524 05:43:50.948272 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0524 05:43:50.948428 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n","I0524 05:43:50.948556 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n","I0524 05:43:50.950461 140275655579520 efficientnet_model.py:147] round_filter input=32 output=48\n","I0524 05:43:50.967812 140275655579520 efficientnet_model.py:147] round_filter input=32 output=48\n","I0524 05:43:50.967938 140275655579520 efficientnet_model.py:147] round_filter input=16 output=24\n","I0524 05:43:51.178820 140275655579520 efficientnet_model.py:147] round_filter input=16 output=24\n","I0524 05:43:51.178976 140275655579520 efficientnet_model.py:147] round_filter input=24 output=40\n","I0524 05:43:51.644019 140275655579520 efficientnet_model.py:147] round_filter input=24 output=40\n","I0524 05:43:51.644220 140275655579520 efficientnet_model.py:147] round_filter input=40 output=64\n","I0524 05:43:52.335108 140275655579520 efficientnet_model.py:147] round_filter input=40 output=64\n","I0524 05:43:52.335330 140275655579520 efficientnet_model.py:147] round_filter input=80 output=128\n","I0524 05:43:53.008525 140275655579520 efficientnet_model.py:147] round_filter input=80 output=128\n","I0524 05:43:53.008742 140275655579520 efficientnet_model.py:147] round_filter input=112 output=176\n","I0524 05:43:53.723449 140275655579520 efficientnet_model.py:147] round_filter input=112 output=176\n","I0524 05:43:53.723676 140275655579520 efficientnet_model.py:147] round_filter input=192 output=304\n","I0524 05:43:54.834419 140275655579520 efficientnet_model.py:147] round_filter input=192 output=304\n","I0524 05:43:54.834614 140275655579520 efficientnet_model.py:147] round_filter input=320 output=512\n","I0524 05:43:55.326668 140275655579520 efficientnet_model.py:147] round_filter input=1280 output=2048\n","I0524 05:43:55.406055 140275655579520 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0524 05:43:55.507789 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0524 05:43:55.507928 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n","I0524 05:43:55.508035 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n","I0524 05:43:55.510139 140275655579520 efficientnet_model.py:147] round_filter input=32 output=56\n","I0524 05:43:55.529111 140275655579520 efficientnet_model.py:147] round_filter input=32 output=56\n","I0524 05:43:55.529238 140275655579520 efficientnet_model.py:147] round_filter input=16 output=32\n","I0524 05:43:55.747802 140275655579520 efficientnet_model.py:147] round_filter input=16 output=32\n","I0524 05:43:55.747998 140275655579520 efficientnet_model.py:147] round_filter input=24 output=40\n","I0524 05:43:56.278625 140275655579520 efficientnet_model.py:147] round_filter input=24 output=40\n","I0524 05:43:56.278844 140275655579520 efficientnet_model.py:147] round_filter input=40 output=72\n","I0524 05:43:56.822075 140275655579520 efficientnet_model.py:147] round_filter input=40 output=72\n","I0524 05:43:56.822277 140275655579520 efficientnet_model.py:147] round_filter input=80 output=144\n","I0524 05:43:57.588076 140275655579520 efficientnet_model.py:147] round_filter input=80 output=144\n","I0524 05:43:57.588368 140275655579520 efficientnet_model.py:147] round_filter input=112 output=200\n","I0524 05:43:58.638849 140275655579520 efficientnet_model.py:147] round_filter input=112 output=200\n","I0524 05:43:58.639074 140275655579520 efficientnet_model.py:147] round_filter input=192 output=344\n","I0524 05:44:00.054255 140275655579520 efficientnet_model.py:147] round_filter input=192 output=344\n","I0524 05:44:00.054478 140275655579520 efficientnet_model.py:147] round_filter input=320 output=576\n","I0524 05:44:00.613951 140275655579520 efficientnet_model.py:147] round_filter input=1280 output=2304\n","I0524 05:44:00.708767 140275655579520 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0524 05:44:00.827820 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0524 05:44:00.827993 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n","I0524 05:44:00.828097 140275655579520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n","I0524 05:44:00.830015 140275655579520 efficientnet_model.py:147] round_filter input=32 output=64\n","I0524 05:44:00.847396 140275655579520 efficientnet_model.py:147] round_filter input=32 output=64\n","I0524 05:44:00.847548 140275655579520 efficientnet_model.py:147] round_filter input=16 output=32\n","I0524 05:44:01.129848 140275655579520 efficientnet_model.py:147] round_filter input=16 output=32\n","I0524 05:44:01.130039 140275655579520 efficientnet_model.py:147] round_filter input=24 output=48\n","I0524 05:44:01.759813 140275655579520 efficientnet_model.py:147] round_filter input=24 output=48\n","I0524 05:44:01.760066 140275655579520 efficientnet_model.py:147] round_filter input=40 output=80\n","I0524 05:44:02.399413 140275655579520 efficientnet_model.py:147] round_filter input=40 output=80\n","I0524 05:44:02.399613 140275655579520 efficientnet_model.py:147] round_filter input=80 output=160\n","I0524 05:44:03.400902 140275655579520 efficientnet_model.py:147] round_filter input=80 output=160\n","I0524 05:44:03.401156 140275655579520 efficientnet_model.py:147] round_filter input=112 output=224\n","I0524 05:44:04.716251 140275655579520 efficientnet_model.py:147] round_filter input=112 output=224\n","I0524 05:44:04.716520 140275655579520 efficientnet_model.py:147] round_filter input=192 output=384\n","I0524 05:44:06.543485 140275655579520 efficientnet_model.py:147] round_filter input=192 output=384\n","I0524 05:44:06.543691 140275655579520 efficientnet_model.py:147] round_filter input=320 output=640\n","I0524 05:44:07.422509 140275655579520 efficientnet_model.py:147] round_filter input=1280 output=2560\n","I0524 05:44:07.522283 140275655579520 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 29.83s\n","I0524 05:44:07.669737 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 29.83s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I0524 05:44:07.677427 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0524 05:44:07.679308 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0524 05:44:07.679908 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0524 05:44:07.681991 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0524 05:44:07.684137 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0524 05:44:07.684712 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0524 05:44:07.685943 140275655579520 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 35.394s\n","\n","OK (skipped=1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ha8GDxxFRu3m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621835054486,"user_tz":-330,"elapsed":517,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"d32db05f-5891-4d33-dee9-baa98a18f564"},"source":["%cd /content/traning_demo/pre-trained-models"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/content/traning_demo/pre-trained-models\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sV8ANeb6jI9T","executionInfo":{"status":"ok","timestamp":1621835064827,"user_tz":-330,"elapsed":514,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["# !rm -r efficientdet_d0_coco17_tpu-32"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"4zZcKeyDcpXB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621835077952,"user_tz":-330,"elapsed":7610,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"d07122eb-113a-4a81-cf3c-c66972e5a9cd"},"source":["# https://drive.google.com/file/d/1C8J5g7zRr3rfbr9db5Q8HCOfXglOG7Kb/view?usp=sharing\n","# Efficientdet pretrained model with wrinkles and darkspots\n","# Comment this line if you want try with custom one\n","\n","!gdown --id 1C8J5g7zRr3rfbr9db5Q8HCOfXglOG7Kb\n","!unzip efdnet_2C.zip\n","!mv /content/traning_demo/pre-trained-models/content/traning_demo/export_model /content/traning_demo/pre-trained-models\n","!mv /content/traning_demo/pre-trained-models/export_model darkspots\n","\n","\n","\n","\n","# https://drive.google.com/file/d/1-0zzdLi3bGk8zlGkAyBhQQPtf_bIuMep/view?usp=sharing\n","# Wrinkles\n","!gdown --id 1-0zzdLi3bGk8zlGkAyBhQQPtf_bIuMep\n","!unzip efdnet.zip\n","!mv /content/traning_demo/pre-trained-models/content/traning_demo/export_model /content/traning_demo/pre-trained-models\n","!mv /content/traning_demo/pre-trained-models/export_model Wrinkles\n","\n","\n","\n","\n","# https://drive.google.com/file/d/1zvHrTZBTLJVsGixF7us2ByPmiGgb3IOj/view?usp=sharing\n","# Darkspots\n","# !gdown --id 1zvHrTZBTLJVsGixF7us2ByPmiGgb3IOj\n","# !unzip darkspots.zip\n","# !mv /content/traning_demo/pre-trained-models/content/fine_tuned_model /content/traning_demo/pre-trained-models\n","# !mv /content/traning_demo/pre-trained-models/fine_tuned_model /content/traning_demo/pre-trained-models/darkspots\n","\n","\n","# Uncomment this if you want to train from scratch\n","# !wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n","# !tar -xf /content/traning_demo/pre-trained-models/efficientdet_d0_coco17_tpu-32.tar.gz"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1C8J5g7zRr3rfbr9db5Q8HCOfXglOG7Kb\n","To: /content/traning_demo/pre-trained-models/efdnet_2C.zip\n","30.7MB [00:00, 50.1MB/s]\n","Archive:  efdnet_2C.zip\n","   creating: content/traning_demo/export_model/\n","  inflating: content/traning_demo/export_model/pipeline.config  \n","   creating: content/traning_demo/export_model/saved_model/\n","   creating: content/traning_demo/export_model/saved_model/assets/\n","  inflating: content/traning_demo/export_model/saved_model/saved_model.pb  \n","   creating: content/traning_demo/export_model/saved_model/variables/\n","  inflating: content/traning_demo/export_model/saved_model/variables/variables.index  \n","  inflating: content/traning_demo/export_model/saved_model/variables/variables.data-00000-of-00001  \n","   creating: content/traning_demo/export_model/checkpoint/\n","  inflating: content/traning_demo/export_model/checkpoint/ckpt-0.index  \n","  inflating: content/traning_demo/export_model/checkpoint/ckpt-0.data-00000-of-00001  \n","  inflating: content/traning_demo/export_model/checkpoint/checkpoint  \n","Downloading...\n","From: https://drive.google.com/uc?id=1-0zzdLi3bGk8zlGkAyBhQQPtf_bIuMep\n","To: /content/traning_demo/pre-trained-models/efdnet.zip\n","30.7MB [00:00, 49.9MB/s]\n","Archive:  efdnet.zip\n","   creating: content/traning_demo/export_model/\n","   creating: content/traning_demo/export_model/checkpoint/\n","  inflating: content/traning_demo/export_model/checkpoint/checkpoint  \n","  inflating: content/traning_demo/export_model/checkpoint/ckpt-0.index  \n","  inflating: content/traning_demo/export_model/checkpoint/ckpt-0.data-00000-of-00001  \n","   creating: content/traning_demo/export_model/saved_model/\n","   creating: content/traning_demo/export_model/saved_model/variables/\n","  inflating: content/traning_demo/export_model/saved_model/variables/variables.data-00000-of-00001  \n","  inflating: content/traning_demo/export_model/saved_model/variables/variables.index  \n","  inflating: content/traning_demo/export_model/saved_model/saved_model.pb  \n","   creating: content/traning_demo/export_model/saved_model/assets/\n","  inflating: content/traning_demo/export_model/pipeline.config  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mpMwBPAndjXU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621835097392,"user_tz":-330,"elapsed":515,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"a357afc6-cbf3-4f0f-d647-96c927bcab0c"},"source":["%cd .."],"execution_count":19,"outputs":[{"output_type":"stream","text":["/content/traning_demo\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9BnQ4u36mbK-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621835101187,"user_tz":-330,"elapsed":593,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"17e807f9-4dec-4bc6-e198-8bfc300c02ff"},"source":["%ls"],"execution_count":20,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mannotations\u001b[0m/  \u001b[01;34mexport_model\u001b[0m/  \u001b[01;34mpre-trained-models\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R4O4qw398e9m","executionInfo":{"status":"ok","timestamp":1621835108452,"user_tz":-330,"elapsed":1029,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["# rm -r /content/traning_demo/dataset\n","!rm -r /content/traning_demo/export_model/\n","!mkdir export_model"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"4LLUhyyjkUi0","executionInfo":{"status":"ok","timestamp":1621835116540,"user_tz":-330,"elapsed":702,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["# https://drive.google.com/file/d/1m3gm3tKGhTQ9a_i_cLD_SS005XMX7ZM_/view?usp=sharing\n","# Download the dataset\n","\n","# !gdown --id 1m3gm3tKGhTQ9a_i_cLD_SS005XMX7ZM_\n","# !unzip /content/traning_demo/dataset.zip"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"QWCame50iaeD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621835123719,"user_tz":-330,"elapsed":2367,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"81979c70-b78d-459b-ae1c-5e9203e315d1"},"source":["# https://drive.google.com/file/d/1C1vNYIgXbxhN1p4NgpKX_BU15DHGOQyw/view?usp=sharing\n","# Download required python files\n","!gdown --id 1C1vNYIgXbxhN1p4NgpKX_BU15DHGOQyw\n","!unzip python_files.zip\n","!mv label_map.pbtxt /content/traning_demo/annotations"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1C1vNYIgXbxhN1p4NgpKX_BU15DHGOQyw\n","To: /content/traning_demo/python_files.zip\n","\r  0% 0.00/6.93k [00:00<?, ?B/s]\r100% 6.93k/6.93k [00:00<00:00, 11.3MB/s]\n","Archive:  python_files.zip\n","  inflating: exporter_main_v2.py     \n","  inflating: generate_tfrecord.py    \n","  inflating: label_map.pbtxt         \n","  inflating: model_main_tf2.py       \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pKIR5ZFXntyv","executionInfo":{"status":"ok","timestamp":1621835128318,"user_tz":-330,"elapsed":4,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["# Create train data:\n","# !python /content/traning_demo/generate_tfrecord.py -x /content/traning_demo/dataset/train -l /content/traning_demo/annotations/label_map.pbtxt -o /content/traning_demo/annotations/train.record\n","\n","# Create test data:\n","# !python /content/traning_demo/generate_tfrecord.py -x /content/traning_demo/dataset/test -l /content/traning_demo/annotations/label_map.pbtxt -o/content/traning_demo/annotations/test.record"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"qHeQ9LI3rHJ5","executionInfo":{"status":"ok","timestamp":1621835131904,"user_tz":-330,"elapsed":582,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["!mkdir my_model"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"vl1efAvFoPac","executionInfo":{"status":"ok","timestamp":1621835136100,"user_tz":-330,"elapsed":4,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["# !cp /content/traning_demo/pre-trained-models/efficientdet_d0_coco17_tpu-32/pipeline.config /content/traning_demo/my_model"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"34PQkbwj_DBp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621835139172,"user_tz":-330,"elapsed":514,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"4f540ead-9165-412c-fcb2-60048b21c80d"},"source":["%cd /content/traning_demo"],"execution_count":27,"outputs":[{"output_type":"stream","text":["/content/traning_demo\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ByvrPYqxyjvx","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1621835141227,"user_tz":-330,"elapsed":10,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"fd04413a-20e1-4191-b5e2-2652dbcaa560"},"source":["%pwd"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/traning_demo'"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"-xSI21Knn-DB","executionInfo":{"status":"ok","timestamp":1621835143269,"user_tz":-330,"elapsed":3,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["# !rm -r /content/traning_demo/export_model\n","# !mkdir export_model"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"VwhFpKveuUua","executionInfo":{"status":"ok","timestamp":1621835145012,"user_tz":-330,"elapsed":3,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["# Train \n","# %%time\n","# !python /content/traning_demo/model_main_tf2.py --model_dir=/content/traning_demo/my_model --pipeline_config_path=/content/traning_demo/my_model/pipeline.config"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"VMQgb-tN3cpW","executionInfo":{"status":"ok","timestamp":1621835146852,"user_tz":-330,"elapsed":2,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["# Exporting model\n","# %%time\n","# !python exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/traning_demo/my_model/pipeline.config --trained_checkpoint_dir /content/traning_demo/my_model --output_directory=/content/traning_demo/export_model"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"WoCKXlzSwQKO","executionInfo":{"status":"ok","timestamp":1621835149208,"user_tz":-330,"elapsed":4,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["# !cp -r /content/traning_demo/pre-trained-models/efficientdet_d0_coco17_tpu-32/. /content/traning_demo/export_model"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"l5WCifioLcZn","colab":{"base_uri":"https://localhost:8080/","height":641},"executionInfo":{"status":"error","timestamp":1621852101276,"user_tz":-330,"elapsed":2839,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"eae2e11f-41a6-4320-b1e9-d6245ff8e8ce"},"source":["%%time\n","\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","import pathlib\n","import tensorflow as tf\n","import cv2\n","import argparse\n","from google.colab.patches import cv2_imshow\n","\n","import time\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","for gpu in gpus:\n","    tf.config.experimental.set_memory_growth(gpu, True)\n","\n","\n","\n","# PROVIDE PATH TO MODEL DIRECTORY\n","PATH_TO_MODEL_DIR_WRINKLES = '/content/traning_demo/pre-trained-models/Wrinkles'\n","\n","MIN_CONF_THRESH = float(0.10)\n","\n","# LOAD THE MODEL\n","\n","PATH_TO_SAVED_MODEL_WRINKLES = PATH_TO_MODEL_DIR_WRINKLES + \"/saved_model\"\n","\n","print('Loading model...', end='')\n","start_time = time.time()\n","\n","# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n","detect_fn_wrinkles = tf.saved_model.load(PATH_TO_SAVED_MODEL_WRINKLES)\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print('Done! Took {} seconds'.format(elapsed_time))\n"],"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-dde870c0952b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nimport os\\nos.environ[\\'TF_CPP_MIN_LOG_LEVEL\\'] = \\'2\\'\\nimport pathlib\\nimport tensorflow as tf\\nimport cv2\\nimport argparse\\nfrom google.colab.patches import cv2_imshow\\n\\nimport time\\nfrom object_detection.utils import label_map_util\\nfrom object_detection.utils import visualization_utils as viz_utils\\n\\ngpus = tf.config.experimental.list_physical_devices(\\'GPU\\')\\nfor gpu in gpus:\\n    tf.config.experimental.set_memory_growth(gpu, True)\\n\\n\\n\\n# PROVIDE PATH TO MODEL DIRECTORY\\nPATH_TO_MODEL_DIR_WRINKLES = \\'/content/traning_demo/pre-trained-models/Wrinkles\\'\\n\\nMIN_CONF_THRESH = float(0.10)\\n\\n# LOAD THE MODEL\\n\\nPATH_TO_SAVED_MODEL_WRINKLES = PATH_TO_MODEL_DIR_WRINKLES + \"/saved_model\"\\n\\nprint(\\'Loading model...\\', end=\\'\\')\\nstart_time = time.time()\\n\\n# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\\ndetect_fn_wrinkles = tf.saved_model.load(PATH_TO_SAVED_MODEL_WRINKLES)\\n\\nend_time = time.time()\\nelapsed_time = end_time - start_time\\nprint(\\'Done! Took {} seconds\\'.format(elapsed_time))'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"z6S0MbQcmlog","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621835252539,"user_tz":-330,"elapsed":34420,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"75759888-cf96-499d-eda0-71d38787a497"},"source":["PATH_TO_MODEL_DIR_DARKSPOTS = '/content/traning_demo/pre-trained-models/darkspots'\n","\n","MIN_CONF_THRESH = float(0.10)\n","\n","# LOAD THE MODEL\n","\n","PATH_TO_SAVED_MODEL_DARKSPOTS = PATH_TO_MODEL_DIR_DARKSPOTS + \"/saved_model\"\n","\n","print('Loading model...', end='')\n","start_time = time.time()\n","\n","# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n","detect_fn_darkspots = tf.saved_model.load(PATH_TO_SAVED_MODEL_DARKSPOTS)\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print('Done! Took {} seconds'.format(elapsed_time))"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Loading model..."],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_119573) with ops with custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_88634) with ops with custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_60359) with ops with custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_55794) with ops with custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_95985) with ops with custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_121193) with ops with custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_84891) with ops with custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_call_func_18624) with ops with custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_92242) with ops with custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_call_func_79375) with ops with custom gradients. Will likely fail if a gradient is requested.\n"],"name":"stderr"},{"output_type":"stream","text":["Done! Took 33.89316201210022 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kK0uqMAIPAI7","executionInfo":{"status":"ok","timestamp":1621835331071,"user_tz":-330,"elapsed":616,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["# import numpy as np\n","# from PIL import Image\n","# import matplotlib.pyplot as plt\n","# import warnings\n","# import cv2\n","# warnings.filterwarnings('ignore')\n","\n","\n","# # PROVIDE PATH TO IMAGE DIRECTORY\n","# IMAGE_PATHS = '/content/traning_demo/dataset/test/5f4278a310117792c164ed4d3e20f586.jpg'\n","\n","# # PROVIDE PATH TO LABEL MAP\n","# PATH_TO_LABELS = '/content/traning_demo/annotations/label_map.pbtxt'\n","\n","# # LOAD LABEL MAP DATA FOR PLOTTING\n","\n","# category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n","#                                                                     use_display_name=True)\n","\n","\n","# print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n","\n","# image = cv2.imread(IMAGE_PATHS)\n","# image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","# image_expanded = np.expand_dims(image_rgb, axis=0)\n","\n","\n","# input_tensor = tf.convert_to_tensor(image)\n","\n","# input_tensor = input_tensor[tf.newaxis, ...]\n","\n","\n","# detections = detect_fn(input_tensor)\n","\n","# num_detections = int(detections.pop('num_detections'))\n","# detections = {key: value[0, :num_detections].numpy()\n","#                for key, value in detections.items()}\n","# detections['num_detections'] = num_detections\n","\n","# detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","# image_with_detections = image.copy()\n","\n","# viz_utils.visualize_boxes_and_labels_on_image_array(\n","#       image_with_detections,\n","#       detections['detection_boxes'],\n","#       detections['detection_classes'],\n","#       detections['detection_scores'],\n","#       category_index,\n","#       use_normalized_coordinates=True,\n","#       max_boxes_to_draw=200,\n","#       min_score_thresh=0.4,\n","#       agnostic_mode=False)\n","\n","# print('Done')\n","# # DISPLAYS OUTPUT IMAGE\n","# cv2_imshow(image_with_detections)\n","# # cv2.imwrite(\"Test.jpg\", image_with_detections)\n","# # CLOSES WINDOW ONCE KEY IS PRESSED"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"i0cwo-bPU1ur"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u_dE7-FxJoZ1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621835341208,"user_tz":-330,"elapsed":4092,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"262b8da2-5944-463f-9f71-cb81eacbdc90"},"source":["!pip install flask-ngrok"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Collecting flask-ngrok\n","  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.25.1)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2020.12.5)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.0.0)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (8.0.0)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.0.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.0)\n","Installing collected packages: flask-ngrok\n","Successfully installed flask-ngrok-0.0.25\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Wvvz6PbJBuV7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621835347762,"user_tz":-330,"elapsed":515,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"1c698ced-cd76-43af-a13a-e616150528cb"},"source":["%cd /content/"],"execution_count":37,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LlcP-buQc-9d","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1621835349514,"user_tz":-330,"elapsed":6,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"63d02046-1f25-4c65-d324-8f2ae940b0fe"},"source":["%pwd"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"FURMCaDrDupp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621835354947,"user_tz":-330,"elapsed":3339,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"7f1aead6-ae73-43d7-dd6f-06a0537c4a3e"},"source":["# https://drive.google.com/file/d/1iWvskjmJD4Xr1x2NtV0TYJm116lh1MHq/view?usp=sharing\n","!gdown --id 1iWvskjmJD4Xr1x2NtV0TYJm116lh1MHq\n","!unzip webpage.zip"],"execution_count":39,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1iWvskjmJD4Xr1x2NtV0TYJm116lh1MHq\n","To: /content/webpage.zip\n","7.40MB [00:00, 34.6MB/s]\n","Archive:  webpage.zip\n","   creating: static/\n","   creating: static/uploads/\n","   creating: static/css/\n","  inflating: static/css/banner1.jpg  \n","  inflating: static/css/style.css    \n","  inflating: static/css/banner3.jpg  \n","  inflating: static/css/img2.jpg     \n","   creating: templates/\n","  inflating: templates/index.html    \n","  inflating: templates/result.html   \n","  inflating: haarcascade_eye.xml     \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xDJ8qG5yCVt8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621835370482,"user_tz":-330,"elapsed":3980,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}},"outputId":"44118ed4-9a63-4256-991d-caafef1bd72d"},"source":["# https://drive.google.com/file/d/1fMsK5T1S0rkzzth5wVcMHDbY4H5gYZTA/view?usp=sharing\n","# Efficientnet model. For pluffy eyes\n","!gdown --id 1fMsK5T1S0rkzzth5wVcMHDbY4H5gYZTA"],"execution_count":40,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1fMsK5T1S0rkzzth5wVcMHDbY4H5gYZTA\n","To: /content/efficientnet.h5\n","16.7MB [00:00, 61.1MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3BO-q_Cov1po","executionInfo":{"status":"ok","timestamp":1621835373873,"user_tz":-330,"elapsed":514,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["# https://drive.google.com/file/d/1OzT-szWYdMFQIVX-KQ7PMLhjuSdgAf7Z/view?usp=sharing\n","# !gdown --id 1OzT-szWYdMFQIVX-KQ7PMLhjuSdgAf7Z"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"acCGDq9IeffD","executionInfo":{"status":"ok","timestamp":1621835378902,"user_tz":-330,"elapsed":1652,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["import os\n","import urllib.request\n","from flask import Flask, flash, request, redirect, url_for, render_template\n","from werkzeug.utils import secure_filename\n","\n","\n","from keras.models import load_model\n","import numpy as np\n","import cv2\n","from PIL import Image\n","from numpy import asarray\n","\n","\n","from flask_ngrok import run_with_ngrok\n","\n","\n","import sys\n","import os\n","import dlib\n","import glob\n","from skimage import io\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ti68Nzz9vM8y","executionInfo":{"status":"ok","timestamp":1621835383192,"user_tz":-330,"elapsed":514,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["# predictor_path = 'shape_predictor_81_face_landmarks.dat'\n","\n","\n","# def face_extract(path):\n","\n","#     img=cv2.imread(path)\n","\n","#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","#     hog_face_detector = dlib.get_frontal_face_detector()\n","\n","#     detector = dlib.get_frontal_face_detector()\n","#     predictor = dlib.shape_predictor(predictor_path)\n","\n","#     dets = detector(img, 0)\n","\n","#     facePoints = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 78, 74, 79, 73, 72, 80, 71, 70, 69, 68, 76, 75, 77, 0]\n","\n","#     for k, d in enumerate(dets):\n","#         shape = predictor(img, d)\n","#         landmarks = np.matrix([[p.x, p.y] for p in shape.parts()])\n","\n","#         mask = np.zeros(img.shape[:2], np.uint8)\n","\n","#         face = np.array([ [shape.parts()[num].x, shape.parts()[num].y] for num in facePoints ])\n","\n","#         cv2.drawContours(mask, [np.array(face)], -1, (255, 255, 255), -1, cv2.LINE_AA)\n","\n","#         dst = cv2.bitwise_and(img, img, mask=mask)\n","\n","#         plt.figure(figsize=(10, 10))\n","#         plt.imshow(dst)\n","#         return dst, img"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"m9otaL9cM9Vw","executionInfo":{"status":"ok","timestamp":1621835411148,"user_tz":-330,"elapsed":516,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import warnings\n","import cv2\n","warnings.filterwarnings('ignore')\n","\n","\n","def effecientDet_wrinkles(path):\n","\n","  # IMAGE_PATHS = path\n","\n","  PATH_TO_LABELS = '/content/traning_demo/annotations/label_map.pbtxt'\n","\n","  category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n","\n","\n","  print('Running inference... ', end='')\n","\n","  # image = cv2.imread(IMAGE_PATHS)\n","  image = path\n","  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","  image_expanded = np.expand_dims(image_rgb, axis=0)\n","\n","\n","  input_tensor = tf.convert_to_tensor(image)\n","\n","  input_tensor = input_tensor[tf.newaxis, ...]\n","\n","\n","  detections = detect_fn_wrinkles(input_tensor)\n","\n","  num_detections = int(detections.pop('num_detections'))\n","  detections = {key: value[0, :num_detections].numpy()\n","                for key, value in detections.items()}\n","  detections['num_detections'] = num_detections\n","\n","  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","  image_with_detections = image.copy()\n","\n","  viz_utils.visualize_boxes_and_labels_on_image_array(\n","        image_with_detections,\n","        detections['detection_boxes'],\n","        detections['detection_classes'],\n","        detections['detection_scores'],\n","        category_index,\n","        use_normalized_coordinates=True,\n","        max_boxes_to_draw=200,\n","        min_score_thresh=0.4,\n","        agnostic_mode=False)\n","\n","  return image_with_detections\n","\n","def effecientDet_darkspots(path):\n","\n","  # IMAGE_PATHS = path\n","\n","  PATH_TO_LABELS = '/content/traning_demo/annotations/label_map.pbtxt'\n","\n","  category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n","\n","\n","  print('Running inference... ', end='')\n","\n","  # image = cv2.imread(IMAGE_PATHS)\n","  image = path\n","  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","  image_expanded = np.expand_dims(image_rgb, axis=0)\n","\n","\n","  input_tensor = tf.convert_to_tensor(image)\n","\n","  input_tensor = input_tensor[tf.newaxis, ...]\n","\n","\n","  detections = detect_fn_darkspots(input_tensor)\n","\n","  num_detections = int(detections.pop('num_detections'))\n","  detections = {key: value[0, :num_detections].numpy()\n","                for key, value in detections.items()}\n","  detections['num_detections'] = num_detections\n","\n","  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","  image_with_detections = image.copy()\n","\n","  viz_utils.visualize_boxes_and_labels_on_image_array(\n","        image_with_detections,\n","        detections['detection_boxes'],\n","        detections['detection_classes'],\n","        detections['detection_scores'],\n","        category_index,\n","        use_normalized_coordinates=True,\n","        max_boxes_to_draw=200,\n","        min_score_thresh=0.4,\n","        agnostic_mode=False)\n","\n","  return image_with_detections"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"QW8KLGQlqt3J","executionInfo":{"status":"ok","timestamp":1621835413915,"user_tz":-330,"elapsed":4,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["# img = effecientDet_wrinkles()"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"5fyi4M29rKwx","executionInfo":{"status":"ok","timestamp":1621835416474,"user_tz":-330,"elapsed":6,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["# file_path = '/content/54196f0c2590c2a308ba2233b31552bf.jpg'\n","# img, orgImg = face_extract(file_path)\n","# plt.imshow(img)\n","# plt.show()\n","\n","\n","# img = effecientDet_wrinkles(img)\n","# cv2_imshow(img)\n","# img = effecientDet_darkspots(img)\n","# cv2_imshow(img)\n","\n","# left_eye, right_eye, eye_points, img = eyes(img)\n","# img, percent = predict_puffyeyes(left_eye, right_eye, eye_points, img, orgImg)\n","# # plt.imshow(img)\n","# # plt.show()\n","# cv2.imwrite(file_path, img)\n","# print(percent)"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kt4-vxvmecMt","executionInfo":{"status":"ok","timestamp":1621835421501,"user_tz":-330,"elapsed":2980,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["model=load_model('efficientnet.h5')\n","eye_cascade=cv2.CascadeClassifier('haarcascade_eye.xml')\n","\n","def eyes(path):\n","\t# img=cv2.imread(path)\n","\timg = path.copy()\n","\teye_rects=eye_cascade.detectMultiScale(img)\n","\teye_points=[]\n","\tfor x,y,w,h in eye_rects:\n","\t\teye_points.append([x,y,w,h])\n","\tx1=eye_points[0][0]\n","\ty1=eye_points[0][1]\n","\tx2=eye_points[0][0]+eye_points[0][2]\n","\ty2=eye_points[0][1]+eye_points[0][3]+30\n","\tleft_eye=img[y1:y2,x1:x2]\n","\tleft_eye=Image.fromarray(left_eye)\n","\tleft_eye=left_eye.resize((224,224))\n","\tleft_eye=asarray(left_eye)\n","\tif len(eye_points)>1:\n","\t\tx1=eye_points[1][0]\n","\t\ty1=eye_points[1][1]\n","\t\tx2=eye_points[1][0]+eye_points[1][2]  \n","\t\ty2=eye_points[1][1]+eye_points[1][3]+30\n","\t\tright_eye=img[y1:y2,x1:x2]\n","\t\tright_eye=Image.fromarray(right_eye)\n","\t\tright_eye=right_eye.resize((224,224))\n","\t\tright_eye=asarray(right_eye)\n","\telse:\n","\t\tright_eye=0\n","\treturn left_eye, right_eye, eye_points, img\n","\n","def predict_puffyeyes(left_eye,right_eye,l1,img, orgImg):\n","\ttest_image=np.expand_dims(left_eye,axis=0)\n","\tresult=model.predict(test_image)\n","\ttempImg = orgImg.copy()\n","\tif result[0][0]>result[0][1]:\n","\t\treturn orgImg, \"No puffy eyes present\"\n","\telse:\n","\t\t#print('left puffy eyes percentage',result[0][1]*100,'%')\n","\t\tb=round(result[0][1]*100,2)\n","\t\tx,y,w,h=l1[0]\n","\t\tcv2.rectangle(tempImg, (x,y), (x+w,y+h+30), (0,255,255), 2)\n","\t\tcv2.putText(tempImg,'Puffy eyes',(x,y+h+15), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,0,25), 1, cv2.LINE_AA)\n","\tif type(right_eye)!=int:\n","\t\ttest_image=np.expand_dims(right_eye,axis=0)\n","\t\tresult=model.predict(test_image)\n","\t\tif result[0][0]>result[0][1]:\n","\t\t\treturn orgImg, \"No puffy eyes present\"\n","\t\telse:\n","\t\t\t#print('right puffy eyes percentage',result[0][1]*100,'%')\n","\t\t\ta=round(result[0][1]*100,1)\n","\t\t\tx,y,w,h=l1[1]\n","\t\t\tcv2.rectangle(tempImg, (x,y), (x+w,y+h+30), (0,255,255), 2)\n","\t\t\tcv2.putText(tempImg,'Puffy eyes',(x,y+h+15), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,0,25), 1, cv2.LINE_AA)\n","\t\t\treturn tempImg, \"\"\n","\treturn orgImg, \"\""],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"3oV_gG4ZM9OU","executionInfo":{"status":"ok","timestamp":1621835424050,"user_tz":-330,"elapsed":4,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["# img, orgImg = face_extract('/content/traning_demo/dataset/test/darkspots(41).jpg')\n","# left_eye, right_eye, eye_points, img = eyes(img)\n","# img, percent = predict_puffyeyes(left_eye, right_eye, eye_points, img, orgImg)\n","# img = effecientDet(img)\n","# print(percent)\n","# plt.imshow(img)"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"A2oBjxDVM9FM","executionInfo":{"status":"ok","timestamp":1621835425892,"user_tz":-330,"elapsed":3,"user":{"displayName":"Isha Srivastava","photoUrl":"","userId":"06837493958827557266"}}},"source":["def load_img(path) :\n","  img=cv2.imread(path)\n","  return img"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"id":"bX_WbfuYGDOG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4bec13d1-ad55-4ff0-f9d7-1dc2bb2cf40f"},"source":["\n","UPLOAD_FOLDER = 'static/uploads/'\n","\n","app = Flask(__name__, template_folder='templates')\n","app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n","\n","run_with_ngrok(app)\n","\n","ALLOWED_EXTENSIONS = set(['png', 'jpg', 'jpeg', 'gif'])\n","\n","def allowed_file(filename):\n","\treturn '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n","\t\n","@app.route('/')\n","def upload_form():\n","\treturn render_template('index.html')\n","\n","@app.route('/', methods=['POST'])\n","def upload_image():\n","\tprint(\"File uploaded\")\n","\tif 'file' not in request.files:\n","\t\treturn redirect(request.url)\n","\tfile = request.files['file']\n","\tif file.filename == '':\n","\t\tflash('No image selected for uploading')\n","\t\treturn redirect(request.url)\n","\tif file and allowed_file(file.filename):\n","\t\tfilename = secure_filename(file.filename)\n","\t\t\n","\n","\t\tfile_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n","\t\tfile.save(file_path)\n","\t\tprint('upload_image filename: ' + filename)\n","\t\tprint(file_path)\n","\t\tpercent = \"\"\n","\t\ttry:\n","\t\t\t\t# img, orgImg = face_extract(file_path)\n","\t\t\t\timg = load_img(file_path)\n","\t\t\t\torgImg = img\n","\n","\t\t\t\timg = effecientDet_wrinkles(img)\n","\t\t\t\t# cv2_imshow(img)\n","\t\t\t\timg = effecientDet_darkspots(img)\n","\t\t\t\t# cv2_imshow(img)\n","\t\t\t\torgImg = img.copy()\n","\t\t\t\tleft_eye, right_eye, eye_points, img = eyes(img)    \n","\t\t\t\timg, percent = predict_puffyeyes(left_eye, right_eye, eye_points, img, img)\n","\t\t\t\t# cv2_imshow(img)\n","\n","\t\t\t\tcv2.imwrite(file_path, img)\n","\t\t\t\tprint(percent)\n","\n","\t\t\t\treturn render_template('result.html', filename=filename, eyes=percent)\n","\t\texcept :\n","\t\t\t\tprint(\"exception in eyes\")\n","\t\t\t\tcv2.imwrite(file_path, img)\n","\t\t\t\treturn render_template('result.html', filename=filename, eyes=\"No puffy eyes present\")\n","\telse:\n","\t\t# flash('Allowed image types are -> png, jpg, jpeg, gif')\n","\t\treturn redirect(request.url)\n","\n","@app.route('/display/<filename>')\n","def display_image(filename):\n","\tprint('display_image filename: ' + filename)\n","\treturn redirect(url_for('static', filename='uploads/' + filename), code=301)\n","\n","if __name__ == \"__main__\":\n","\tapp.run()"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n","\u001b[2m   Use a production WSGI server instead.\u001b[0m\n"," * Debug mode: off\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"],"name":"stderr"},{"output_type":"stream","text":[" * Running on http://c44229fcd1fb.ngrok.io\n"," * Traffic stats available on http://127.0.0.1:4040\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Op0UNzia1SXY"},"source":[""],"execution_count":null,"outputs":[]}]}